{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giridharpalla/Bhagavad-Gita-AI/blob/main/Practise/prompt_engineering/RAG_System_End_to_End.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWC8XPMqhM3e"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IyjiWKwgW0s",
        "outputId": "0bf4a77a-f595-42f9-9be5-4caeca49f33b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter the api key··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"enter the api key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qsmf-WS_g9wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b00f50c-30cb-44d5-cbe1-a0b6b0fd81ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.72)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.98.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.28\n"
          ]
        }
      ],
      "source": [
        "#!pip install langchain-openai\n",
        "from langchain_openai import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "8oWPN9OMoQXf"
      },
      "outputs": [],
      "source": [
        "openai_embedd_model = OpenAIEmbeddings(model = \"text-embedding-ada-002\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEo00PKToQXg"
      },
      "source": [
        "# Load and Process JSON Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a1FxOGHloQXg",
        "outputId": "d9d2ec9c-565e-4ba6-e91f-494c66411ffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slpUggTJoQXh",
        "outputId": "843c0f82-d119-4ed8-fc0a-fc04413655c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jq\n",
            "  Downloading jq-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Downloading jq-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/754.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/754.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.3/754.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jq\n",
            "Successfully installed jq-1.10.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#!pip install langchain\n",
        "\n",
        "#!pip install -U langchain-community\n",
        "\n",
        "!pip install jq\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vpomS_RnoQXi"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import JSONLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TrynQyCuoQXj"
      },
      "outputs": [],
      "source": [
        "loader = JSONLoader(file_path=\"wikidata_rag_demo.jsonl\",\n",
        "                    jq_schema = '.',text_content=False,json_lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_docs = loader.load()"
      ],
      "metadata": {
        "id": "B5FJzcctq36f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_docs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWJ7Kwp7q93z",
        "outputId": "6d87887d-e156-4349-d863-af4c850bf416"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/wikidata_rag_demo.jsonl', 'seq_num': 2}, page_content='{\"id\": \"86394\", \"title\": \"Dattatreya\", \"paragraphs\": [\"Dattatreya is the God who is an incarnation of the Divine Trinity Brahma, Vishnu and Siva. The word Datta means \\\\\"Given\\\\\", Datta is called so because the divine trinity have \\\\\"given\\\\\" themselves in the form of a son to the sage couple Guru Atri and Mata Anusuya. He is the son of Guru Atri, hence the name \\\\\"Atreya.\\\\\"\", \"In the Nath tradition, Dattatreya is seen as an Avatar or incarnation of the Lord Shiva and as the Adi-Guru (First Teacher) of the Adi-Nath sampradaya of the Nathas. Although Dattatreya was at first a \\\\\"Lord of Yoga\\\\\" with Tantric traits, he was adapted and assimilated into the more devotional cults; while still worshiped by millions of Hindus, he is approached more as a benevolent God than as a teacher of the highest essence of Indian thought.\", \"Though the Dattatreya of the Natha tradition coexisted and intermingled with the Puranic, Brahmanical tradition of the Datta sampradaya, here we shall focus almost exclusively on the earlier Tantric manifestation of Datta. Shri Gurudev Mahendranath had no doubt that Dattatreya was an historical figure. He stated that Datta was born on Wednesday, the fourteenth day of the full moon in the month of Margasirsa, though he does not mention the year.\"]}')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain.docstore.document import Document\n",
        "wiki_doc_processed = []\n",
        "\n",
        "for doc in wiki_docs:\n",
        "  doc = json.loads(doc.page_content)\n",
        "  metadata = {\"id\": doc['id'],\"title\":doc['title'],'source' : 'wikipedia'}\n",
        "  data = ''.join(doc['paragraphs'])\n",
        "  wiki_doc_processed.append(Document(page_content=data,metadata=metadata))"
      ],
      "metadata": {
        "id": "bLCubeaVvV1i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_doc_processed[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E54LKQNpxKlx",
        "outputId": "349d5a36-24a3-4235-8dc1-fad7264c8ba2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'id': '86394', 'title': 'Dattatreya', 'source': 'wikipedia'}, page_content='Dattatreya is the God who is an incarnation of the Divine Trinity Brahma, Vishnu and Siva. The word Datta means \"Given\", Datta is called so because the divine trinity have \"given\" themselves in the form of a son to the sage couple Guru Atri and Mata Anusuya. He is the son of Guru Atri, hence the name \"Atreya.\"In the Nath tradition, Dattatreya is seen as an Avatar or incarnation of the Lord Shiva and as the Adi-Guru (First Teacher) of the Adi-Nath sampradaya of the Nathas. Although Dattatreya was at first a \"Lord of Yoga\" with Tantric traits, he was adapted and assimilated into the more devotional cults; while still worshiped by millions of Hindus, he is approached more as a benevolent God than as a teacher of the highest essence of Indian thought.Though the Dattatreya of the Natha tradition coexisted and intermingled with the Puranic, Brahmanical tradition of the Datta sampradaya, here we shall focus almost exclusively on the earlier Tantric manifestation of Datta. Shri Gurudev Mahendranath had no doubt that Dattatreya was an historical figure. He stated that Datta was born on Wednesday, the fourteenth day of the full moon in the month of Margasirsa, though he does not mention the year.')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U langchain langchain-community\n",
        "\n",
        "#!pip install langchain\n",
        "\n",
        "#!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHFSm2BA0uvQ",
        "outputId": "5237c573-e704-4155-d37f-6d623bab4149"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "def create_simple_chunks(filepath, chunk_size=3500, chunk_overlap=500):\n",
        "  print(\"Loading Pages:\", filepath)\n",
        "  loader = PyMuPDFLoader(filepath)\n",
        "  pages = loader.load()\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
        "  )\n",
        "  print(\"Chunking Pages :\", filepath)\n",
        "  doc_chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "\n",
        "  print(\"Finished Processing: \", filepath)\n",
        "  print()\n",
        "  return doc_chunks"
      ],
      "metadata": {
        "id": "ovNPtr12y-Nj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "pdf_files = glob(\"*.pdf\")\n",
        "pdf_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NYm1MOE15_N",
        "outputId": "017441f4-9eae-47f6-c590-f9244bd27537"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vision_transformer.pdf',\n",
              " 'cnn_paper.pdf',\n",
              " 'resnet_paper.pdf',\n",
              " 'attention_paper.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper_docs=[]\n",
        "\n",
        "for fp in pdf_files:\n",
        "  paper_docs.extend(create_simple_chunks(fp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_Rf8kJT3SjG",
        "outputId": "61c8e1ed-5c92-4834-9abb-de291dca6ab0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Pages: vision_transformer.pdf\n",
            "Chunking Pages : vision_transformer.pdf\n",
            "Finished Processing:  vision_transformer.pdf\n",
            "\n",
            "Loading Pages: cnn_paper.pdf\n",
            "Chunking Pages : cnn_paper.pdf\n",
            "Finished Processing:  cnn_paper.pdf\n",
            "\n",
            "Loading Pages: resnet_paper.pdf\n",
            "Chunking Pages : resnet_paper.pdf\n",
            "Finished Processing:  resnet_paper.pdf\n",
            "\n",
            "Loading Pages: attention_paper.pdf\n",
            "Chunking Pages : attention_paper.pdf\n",
            "Finished Processing:  attention_paper.pdf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper_docs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkMXwfW54piG",
        "outputId": "a125871f-3363-4603-aceb-cff53478aacb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-06-04T00:19:58+00:00', 'source': 'vision_transformer.pdf', 'file_path': 'vision_transformer.pdf', 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-06-04T00:19:58+00:00', 'trapped': '', 'modDate': 'D:20210604001958Z', 'creationDate': 'D:20210604001958Z', 'page': 1}, page_content='Published as a conference paper at ICLR 2021\\ninherent to CNNs, such as translation equivariance and locality, and therefore do not generalize well\\nwhen trained on insufﬁcient amounts of data.\\nHowever, the picture changes if the models are trained on larger datasets (14M-300M images). We\\nﬁnd that large scale training trumps inductive bias. Our Vision Transformer (ViT) attains excellent\\nresults when pre-trained at sufﬁcient scale and transferred to tasks with fewer datapoints. When\\npre-trained on the public ImageNet-21k dataset or the in-house JFT-300M dataset, ViT approaches\\nor beats state of the art on multiple image recognition benchmarks. In particular, the best model\\nreaches the accuracy of 88.55% on ImageNet, 90.72% on ImageNet-ReaL, 94.55% on CIFAR-100,\\nand 77.63% on the VTAB suite of 19 tasks.\\n2\\nRELATED WORK\\nTransformers were proposed by Vaswani et al. (2017) for machine translation, and have since be-\\ncome the state of the art method in many NLP tasks. Large Transformer-based models are often\\npre-trained on large corpora and then ﬁne-tuned for the task at hand: BERT (Devlin et al., 2019)\\nuses a denoising self-supervised pre-training task, while the GPT line of work uses language mod-\\neling as its pre-training task (Radford et al., 2018; 2019; Brown et al., 2020).\\nNaive application of self-attention to images would require that each pixel attends to every other\\npixel. With quadratic cost in the number of pixels, this does not scale to realistic input sizes. Thus,\\nto apply Transformers in the context of image processing, several approximations have been tried in\\nthe past. Parmar et al. (2018) applied the self-attention only in local neighborhoods for each query\\npixel instead of globally. Such local multi-head dot-product self attention blocks can completely\\nreplace convolutions (Hu et al., 2019; Ramachandran et al., 2019; Zhao et al., 2020). In a different\\nline of work, Sparse Transformers (Child et al., 2019) employ scalable approximations to global self-\\nattention in order to be applicable to images. An alternative way to scale attention is to apply it in\\nblocks of varying sizes (Weissenborn et al., 2019), in the extreme case only along individual axes (Ho\\net al., 2019; Wang et al., 2020a). Many of these specialized attention architectures demonstrate\\npromising results on computer vision tasks, but require complex engineering to be implemented\\nefﬁciently on hardware accelerators.\\nMost related to ours is the model of Cordonnier et al. (2020), which extracts patches of size 2 × 2\\nfrom the input image and applies full self-attention on top. This model is very similar to ViT,\\nbut our work goes further to demonstrate that large scale pre-training makes vanilla transformers\\ncompetitive with (or even better than) state-of-the-art CNNs. Moreover, Cordonnier et al. (2020)\\nuse a small patch size of 2 × 2 pixels, which makes the model applicable only to small-resolution\\nimages, while we handle medium-resolution images as well.\\nThere has also been a lot of interest in combining convolutional neural networks (CNNs) with forms\\nof self-attention, e.g. by augmenting feature maps for image classiﬁcation (Bello et al., 2019) or by\\nfurther processing the output of a CNN using self-attention, e.g. for object detection (Hu et al., 2018;\\nCarion et al., 2020), video processing (Wang et al., 2018; Sun et al., 2019), image classiﬁcation (Wu\\net al., 2020), unsupervised object discovery (Locatello et al., 2020), or uniﬁed text-vision tasks (Chen')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(wiki_doc_processed))\n",
        "print(len(paper_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNafN5NM45v4",
        "outputId": "4c163d95-790e-409f-8cef-85d14d4a8846"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1801\n",
            "79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_docs = wiki_doc_processed + paper_docs"
      ],
      "metadata": {
        "id": "5NVtZqfU5ETf"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(total_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wczbDuW5LlS",
        "outputId": "faa0efc3-035e-4f27-e3c9-5a6fa4f31c3f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1880"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding and Chroma DB(Vector Database storage/index)"
      ],
      "metadata": {
        "id": "8bXktNey7YdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-chroma\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBc4hIEJ7xef",
        "outputId": "ebdf2746-a49b-4a70-831a-7eecb0873cd6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.70 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (0.3.72)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (2.0.2)\n",
            "Collecting chromadb>=1.0.9 (from langchain-chroma)\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.14.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.21.4)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (3.11.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.25.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.70->langchain-chroma) (0.4.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.70->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.70->langchain-chroma) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.70->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.70->langchain-chroma) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.70->langchain-chroma) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (0.34.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.6.1)\n",
            "Downloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
            "Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=4a3a77f2717f7a68d270a008f525771b0d1f2aa6e610694755cf7e3660bffc8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-chroma\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain-chroma-0.2.5 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "chroma_db = Chroma.from_documents(documents=total_docs,embedding= openai_embedd_model,\n",
        "                                 collection_name= 'mydb',\n",
        "                                  collection_metadata={\"hnsw:space\":\"cosine\"},\n",
        "                                  persist_directory=\"./mydb\")"
      ],
      "metadata": {
        "id": "PRWXnfx27Olp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the Vector DB from the Disk"
      ],
      "metadata": {
        "id": "nrnIUY_A8vnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Vector DB from disk\n",
        "### This is just to show once you have a vector database on your disk, you can just load and create a connection to it anytime"
      ],
      "metadata": {
        "id": "mLkCZeLJ9hg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chroma_db = Chroma(collection_name=\"mydb\",embedding_function=openai_embedd_model,\n",
        "                   persist_directory=\"./mydb\")"
      ],
      "metadata": {
        "id": "KEefFKdE7WnL"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chroma_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpkU3e3-9KSU",
        "outputId": "c9b6ad50-3986-4255-b13a-2e361b2495ef"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7a567bf67550>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Semantic Similarity based Retrival"
      ],
      "metadata": {
        "id": "-5Wj1oEB9W-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_retriver = chroma_db.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":5})"
      ],
      "metadata": {
        "id": "Nk1O1qXf9WGS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S_6SuQEcBsHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display,Markdown\n",
        "\n",
        "def display_docs(docs):\n",
        "  for doc in docs:\n",
        "    print(\"metadataa: \", doc.metadata)\n",
        "    print(\"content:\")\n",
        "    display(Markdown(doc.page_content))"
      ],
      "metadata": {
        "id": "WVcGkKOq_3KJ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who is narendra modi\"\n",
        "\n",
        "top_docs = similarity_retriver.invoke(query)\n",
        "\n",
        "display_docs(top_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "a4h6govkASSD",
        "outputId": "777d6b1c-f548-4687-f007-d4d19b00a4dc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadataa:  {'title': 'E. Ahamed', 'source': 'wikipedia', 'id': '569968'}\n",
            "content:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "E. Ahamed (29 April 1938 – 1 February 2017) was an Indian politician. He served as Minister of State for External Affairs in the Manmohan Singh government from 2004 through 2014. He represented the Malappuram Lok Sabha constituency of Kerala and is the National President of the Indian Union Muslim League (IUML) from 2009 until his death in 2017. He was born in Malappuram, Kerala.Ahamed died at the age of 78 at a hospital in Delhi, India after suffering from cardiac arrest during President Pranab Mukherjee's address to the parliament."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadataa:  {'id': '767237', 'title': 'Konijeti Rosaiah', 'source': 'wikipedia'}\n",
            "content:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Konijeti Rosaiah (born 4 July 1933) is an Indian politician. He was was Chief Minister of Andhra Pradesh from 2009 to 2010 and Governor of Tamil Nadu from 2011 to 2016. He was an MLC, MLA and MP from the Indian National Congress."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadataa:  {'title': 'Sultan Ahmed', 'source': 'wikipedia', 'id': '596196'}\n",
            "content:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sultan Ahmed (6 June 1953 – 4 September 2017) was an Indian politician. He was born in Kolkata, India. He served as the Union Minister of State for Tourism in the Council of Ministers of the Republic of India. He was elected to the 15th Lok Sabha from Uluberia (Lok Sabha constituency) on a Trinamool Congress ticket. He had previously been a 2-time Congress MLA for Entally ( in1987–91 and once again in 1996–2001).Ahmed died at a hospital in Kolkata after suffering from cardiac arrest on 4 September 2017 at the age of 64."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadataa:  {'id': '367170', 'source': 'wikipedia', 'title': 'Shahnawaz Khan Mamdot'}\n",
            "content:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sir Shahnawaz Khan Mamdot (1883 - March 28, 1942) was a Punjabi landowner and supporter of the All India Muslim League (AIML) in its demand for a separate Pakistan. In March 1940, he was one of the principal hosts for the AIML's famous Lahore Conference."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadataa:  {'title': 'Mimlu Sen', 'source': 'wikipedia', 'id': '798128'}\n",
            "content:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Mimlu Sen (born 1949) is an Indian author, translator, musician, composer and producer.Sen was born in Shillong, Meghalaya, India. During the 1960s and 1970s she studying in Kolkata and participating in street protests demanding an end of Vietnam War. She has been jailed for Naxalite movement.Sen was published her first book \"Baulsphere\" in 2009. The following year it was published as \"The Honey Gatherers\". Piers Moore Ede stated that \"The Honey Gatherers\" recounts Sen's adventures in rural Bengal."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(top_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiWHXEzbBFqt",
        "outputId": "a3e97d6b-1a48-4a14-f20c-6d1b493972b8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Augumetnation / Enhance your prompt"
      ],
      "metadata": {
        "id": "UQCD2g-cDNsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
        "            Answer the following question using only the following pieces of retrieved context.\n",
        "            If the answer is not in the context, do not make up answers, just say that you don't know.\n",
        "            Keep the answer detailed and well formatted based on the information from the context.\n",
        "\n",
        "            Question:\n",
        "            {question}\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Answer:\n",
        "            \"\"\"\n",
        "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
      ],
      "metadata": {
        "id": "iQRJSweYDM78"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build the RAG pipeline"
      ],
      "metadata": {
        "id": "tAPx-cLJETpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatLLM = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "exdnvVKMEQ49"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "qa_rag_chain =({\"context\": (similarity_retriver | format_docs), \"question\": RunnablePassthrough()} | rag_prompt_template | chatLLM)"
      ],
      "metadata": {
        "id": "puc-u-ECE_bN"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is machine learning\"\n",
        "\n",
        "reesult = qa_rag_chain.invoke(query)\n",
        "\n",
        "\n",
        "display(Markdown(reesult.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "lQJgD6xnGOVd",
        "outputId": "f69354f9-5b29-4c8e-bd6f-a7c4fcf44c30"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Machine learning is a subfield of computer science that provides computers with the ability to learn without being explicitly programmed. The concept was introduced by Arthur Samuel in 1959 and is rooted in artificial intelligence. Machine learning focuses on the study and construction of algorithms that can learn from data and make predictions or decisions based on that data. These algorithms follow programmed instructions but can also adapt and improve their performance by building models from sample inputs.\n\nMachine learning is particularly useful in scenarios where designing and programming explicit algorithms is impractical. Common applications include spam filtering, detecting network intrusions or malicious insiders, optical character recognition (OCR), search engines, and computer vision.\n\nThere are different types of machine learning, including:\n\n1. **Supervised Learning**: This involves inferring a function from labeled training data, where the results are known beforehand. The system learns to produce a \"classifier\" based on the training data and the expected outcomes.\n\n2. **Deep Learning**: A subset of machine learning that utilizes neural networks, particularly those with multiple layers (deep neural networks). Deep learning is effective for complex tasks such as speech recognition, image understanding, and handwriting recognition. It processes information in a hierarchical manner, with each layer extracting increasingly abstract features.\n\n3. **Reinforcement Learning (RL)**: This approach teaches a \"software agent\" how to behave in an environment by providing feedback on its performance. Unlike supervised learning, RL does not provide correct input-output pairs; instead, it learns through trial and error, balancing exploration and exploitation.\n\nOverall, machine learning enables computers to improve their performance on tasks by learning from data, making it a crucial component of modern artificial intelligence systems."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is CNN? explain in detail step by step\"\n",
        "\n",
        "reesult = qa_rag_chain.invoke(query)\n",
        "\n",
        "\n",
        "display(Markdown(reesult.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "Y1uDthblHyrj",
        "outputId": "ff14b6ce-4a20-4b13-a03b-081123276384"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**What is CNN?**\n\nCNN stands for Convolutional Neural Network, which is a specialized type of Artificial Neural Network (ANN) primarily used for image-driven pattern recognition tasks. Below is a detailed step-by-step explanation of CNNs based on the provided context.\n\n### Step 1: Understanding Artificial Neural Networks (ANNs)\n- **Definition**: ANNs are computational models inspired by the biological nervous systems, such as the human brain. They consist of interconnected nodes (neurons) that work together to learn from input data and optimize output.\n- **Structure**: ANNs typically have an input layer, one or more hidden layers, and an output layer. The input is processed through these layers, where each neuron makes decisions based on the previous layer's output.\n\n### Step 2: Introduction to CNNs\n- **Purpose**: CNNs are designed to handle complex image recognition tasks more effectively than traditional ANNs. They simplify the process of learning from images by using a specific architecture tailored for spatial data.\n- **Architecture**: CNNs consist of three main types of layers:\n  1. **Convolutional Layers**: These layers apply convolution operations to the input, allowing the network to learn spatial hierarchies of features. Each neuron in a convolutional layer connects to a small region of the input, which helps in detecting patterns such as edges or textures.\n  2. **Pooling Layers**: These layers reduce the dimensionality of the data, helping to decrease the computational load and control overfitting. Pooling layers summarize the features detected in the convolutional layers.\n  3. **Fully-Connected Layers**: These layers connect every neuron in one layer to every neuron in the next layer, allowing for the final classification based on the features extracted by the previous layers.\n\n### Step 3: CNN Functionality\n- **Input Layer**: The input layer holds the pixel values of the image, typically represented as a multidimensional array (e.g., height x width x depth).\n- **Convolutional Operation**: In the convolutional layer, neurons compute the output by performing a scalar product between their weights and the corresponding region of the input volume. This operation helps in extracting features from the image.\n- **Activation Function**: The Rectified Linear Unit (ReLu) is commonly used as an activation function in CNNs. It introduces non-linearity into the model, allowing it to learn complex patterns.\n- **Output Layer**: The final output layer condenses the learned features into class scores, indicating the likelihood of the input belonging to each class.\n\n### Step 4: Example of CNN Architecture\n- A simplified CNN architecture for a task like MNIST classification might include:\n  - An input layer that receives the image data.\n  - A convolutional layer that processes the image to extract features.\n  - A pooling layer that reduces the dimensionality of the feature maps.\n  - One or more fully-connected layers that interpret the features and produce the final classification output.\n\n### Conclusion\nCNNs are a powerful tool in the field of machine learning, particularly for image analysis and recognition tasks. Their architecture, which includes convolutional, pooling, and fully-connected layers, allows them to effectively learn and generalize from visual data."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"do you learnbday institute in bengaluru\"\n",
        "\n",
        "reesult = qa_rag_chain.invoke(query)\n",
        "\n",
        "\n",
        "display(Markdown(reesult.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "PKzgZXPBIP8n",
        "outputId": "5ffb666c-6512-4152-8ca2-fe8e65c4fc8b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I don't know."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building RAG System using LlamaIndex\n",
        "\n",
        "##### https://www.llamaindex.ai/"
      ],
      "metadata": {
        "id": "BMa6VeuvL904"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data INGESTION (data loading, chunking+nodes, embedding)\n",
        "2. Indexing\n",
        "3. Retriever\n",
        "4. Response Synthesizer\n",
        "5. Querying"
      ],
      "metadata": {
        "id": "bIx2wBPPL_46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U llama-index"
      ],
      "metadata": {
        "id": "uCfGe0HOMApJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"enter the api key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtZHomwmMeSF",
        "outputId": "28b5ac2d-d884-42d0-fe5c-4ebe2423f4a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter the api key··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 - Data Ingestion\n",
        "### Data Loaders"
      ],
      "metadata": {
        "id": "7-XuCiCUOPiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader"
      ],
      "metadata": {
        "id": "QeqhhgAuMto4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "pdf_files = glob(\"*.pdf\")\n",
        "pdf_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPGZVq1tNIrD",
        "outputId": "a1ff51bc-4136-4ed1-d5c6-afdd493e1c87"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vision_transformer.pdf',\n",
              " 'cnn_paper.pdf',\n",
              " 'resnet_paper.pdf',\n",
              " 'attention_paper.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(input_files=pdf_files).load_data()"
      ],
      "metadata": {
        "id": "EJsvHaIXNeO8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAOR4Bn2NlIC",
        "outputId": "c4c2228c-1261-4a9f-d336-8ddaec036592"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[1].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IETHxGHeN8Cp",
        "outputId": "e12afe89-48c8-4fcc-e695-241a8e920349"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page_label': '2',\n",
              " 'file_name': 'vision_transformer.pdf',\n",
              " 'file_path': 'vision_transformer.pdf',\n",
              " 'file_type': 'application/pdf',\n",
              " 'file_size': 3743814,\n",
              " 'creation_date': '2025-08-01',\n",
              " 'last_modified_date': '2025-08-01'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chunking"
      ],
      "metadata": {
        "id": "-dJTqkHpPNK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter, TokenTextSplitter"
      ],
      "metadata": {
        "id": "mzhzJu5RPPuk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = SentenceSplitter(chunk_size=80, chunk_overlap=20)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "5RnXPPFwPZw5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(documents))\n",
        "print(len(nodes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm1mJDL_PeyS",
        "outputId": "68e0fb87-c0f8-4f76-b644-3cdfa2178260"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "1177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding model"
      ],
      "metadata": {
        "id": "2U8KVd9QQZcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.openai import OpenAIEmbedding"
      ],
      "metadata": {
        "id": "xllF1v_aQZEj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "45udufmgQhw3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#indexing/ Vector Storage"
      ],
      "metadata": {
        "id": "YhUmEpnsQ9Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex"
      ],
      "metadata": {
        "id": "aQiSONHBQtJ9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex(nodes,embed_model=embed_model)"
      ],
      "metadata": {
        "id": "aOHmvw7mRHMS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrival"
      ],
      "metadata": {
        "id": "gTZzsmitR0L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI"
      ],
      "metadata": {
        "id": "AU8vtvtCR2QG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model = \"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "8I1PfcvHRz-V"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriver = index.as_retriever()"
      ],
      "metadata": {
        "id": "iAnF2XZmSEWI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrived_nodes = retriver.retrieve(\"who is narendra modi\")\n"
      ],
      "metadata": {
        "id": "vKgVf_1BSv3N"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrived_nodes[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSlXPHf7TSGs",
        "outputId": "ee925da3-7be2-4665-f40a-9019e4dd9b38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page_label': '11',\n",
              " 'file_name': 'vision_transformer.pdf',\n",
              " 'file_path': 'vision_transformer.pdf',\n",
              " 'file_type': 'application/pdf',\n",
              " 'file_size': 3743814,\n",
              " 'creation_date': '2025-08-01',\n",
              " 'last_modified_date': '2025-08-01'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in retrived_nodes:\n",
        "  print(i.metadata)\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1iG_A6QTVwL",
        "outputId": "80ed606d-3955-4d55-ecc7-8337d2e923a6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page_label': '11', 'file_name': 'vision_transformer.pdf', 'file_path': 'vision_transformer.pdf', 'file_type': 'application/pdf', 'file_size': 3743814, 'creation_date': '2025-08-01', 'last_modified_date': '2025-08-01'}\n",
            "Node ID: 0a3e4be9-8012-4795-9a69-773c84972c23\n",
            "Text: Jawahar. Cats and dogs. InCVPR, 2012. Niki Parmar, Ashish\n",
            "Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku,\n",
            "and Dustin Tran. Image transformer.\n",
            "Score:  0.690\n",
            "\n",
            "{'page_label': '12', 'file_name': 'vision_transformer.pdf', 'file_path': 'vision_transformer.pdf', 'file_type': 'application/pdf', 'file_size': 3743814, 'creation_date': '2025-08-01', 'last_modified_date': '2025-08-01'}\n",
            "Node ID: bf7fb402-7505-47e0-956f-07c0f90a176f\n",
            "Text: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,\n",
            "Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.\n",
            "Attention is all you need. In NIPS, 2017.\n",
            "Score:  0.686\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#response synthesizer"
      ],
      "metadata": {
        "id": "Ya23Ict7UAKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import get_response_synthesizer\n",
        "response_synthesizer = get_response_synthesizer(llm=llm)"
      ],
      "metadata": {
        "id": "TBaMn4sHTvNQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Querying"
      ],
      "metadata": {
        "id": "IPSnytpLUNzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display,Markdown\n",
        "query_engine = index.as_query_engine(llm=llm, response_synthesizer=response_synthesizer)\n",
        "response = query_engine.query(\"What is Transformers?\")\n",
        "display(Markdown(response.response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "0jKA4eUWUNPB",
        "outputId": "cde079bb-dd5d-40fb-f4b9-82c7522e50cb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Transformers are a type of model introduced for machine translation that utilize self-attention mechanisms to compute representations of input and output data. They do not rely on sequence-aligned recurrent neural networks (RNNs) or convolutional methods, making them distinct in their approach to processing information."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"is bengaluru overcrowded\")\n",
        "display(Markdown(response.response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "Yi7Ea8WtUZNq",
        "outputId": "b69e0c7d-a95d-41dc-8bb8-a4362911da23"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The provided information does not address the topic of whether Bengaluru is overcrowded. Therefore, I cannot provide an answer to that query."
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}